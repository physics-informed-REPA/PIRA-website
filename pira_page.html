<!doctype html>
<html lang="en">
    <head>
        <title>Physics-Informed Representation Alignment (PIRA)</title>
        <link rel="icon" type="image/x-icon" href="static/img/icons/tower_icon.png">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:url" content="https://physics-informed-repa.github.io/PIRA-website/" />
        <meta property="og:image" content="https://physics-informed-repa.github.io/PIRA-website/static/img/preview.png" />
        <meta property="og:title" content="Physics-Informed Representation Alignment (PIRA)" />
        <meta property="og:description" content="A framework for instilling targeted, interpretable physical knowledge into pre-trained Video Diffusion Models by re-purposing the model's native VAE as a physics encoder." />

        <meta name="twitter:url" content="https://physics-informed-repa.github.io/PIRA-website/" />
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:image" content="https://physics-informed-repa.github.io/PIRA-website/static/img/preview.png" />
        <meta name="twitter:title" content="Physics-Informed Representation Alignment (PIRA)" />
        <meta name="twitter:description" content="Grounding Video Diffusion Models in the Causal Principles of the Physical World." />

        <script src="./static/js/distill_template.v2.js"></script>

        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="https://d3js.org/d3-collection.v1.min.js"></script>
        <script src="https://rawgit.com/nstrayer/slid3r/master/dist/slid3r.js"></script>
        <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>

        <link rel="stylesheet" href="./static/css/style.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@9.0.0/swiper-bundle.min.css">
        <script src="https://cdn.jsdelivr.net/npm/swiper@9.0.0/swiper-bundle.min.js"></script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
        
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>

        <!-- medium zoom https://github.com/francoischalifour/medium-zoom -->
        <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js"></script>  <!-- jquery -->
        <script defer src="./static/js/medium-zoom.min.js"></script>
        <script defer src="./static/js/zoom.js"></script>
        
        <!-- Interactive Video Comparison & Table Styles -->
        <style>
            .split-selector { margin-bottom: 20px; text-align: center; }
            .split-btn { background: #f8f9fa; border: 2px solid #dee2e6; color: #495057; padding: 10px 20px; margin: 0 5px; border-radius: 6px; cursor: pointer; font-weight: 500; transition: all 0.3s ease; }
            .split-btn:hover { background: #e9ecef; border-color: #adb5bd; }
            .split-btn.active { background: #4a14f1; border-color: #4a14f1; color: white; }
            .navigation-controls { display: flex; align-items: center; justify-content: center; gap: 20px; max-width: 400px; margin: 0 auto; }
            .nav-arrow { background: #4a14f1; border: 2px solid #4a14f1; color: white; padding: 12px 16px; border-radius: 8px; cursor: pointer; font-weight: 600; font-size: 18px; transition: all 0.3s ease; min-width: 50px; }
            .nav-arrow:hover:not(:disabled) { background: #3a0fd1; border-color: #3a0fd1; transform: translateY(-2px); }
            .nav-arrow:disabled { background: #e9ecef; border-color: #dee2e6; color: #adb5bd; cursor: not-allowed; transform: none; }
            .instance-dropdown { background: white; border: 2px solid #4a14f1; color: #333; padding: 8px 12px; border-radius: 8px; cursor: pointer; font-weight: 600; font-size: 16px; min-width: 140px; text-align: center; transition: all 0.3s ease; appearance: none; background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 20 20'%3e%3cpath stroke='%234a14f1' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.5' d='m6 8 4 4 4-4'/%3e%3c/svg%3e"); background-position: right 8px center; background-repeat: no-repeat; background-size: 16px; padding-right: 32px; }
            .instance-dropdown:hover { border-color: #3a0fd1; transform: translateY(-1px); }
            .instance-dropdown:focus { outline: none; border-color: #3a0fd1; box-shadow: 0 0 0 3px rgba(74, 20, 241, 0.1); }
            .video-comparison { display: flex; justify-content: center; margin-top: 20px; }
            .comparison-row { display: flex; gap: 20px; flex-wrap: wrap; justify-content: center; max-width: 1000px; }
            .video-column { flex: 1; min-width: 250px; text-align: center; }
            .method-label { margin-bottom: 10px; font-weight: 600; color: #333; font-size: 14px; }
            .video-column video { box-shadow: 0 2px 8px rgba(0,0,0,0.1); border: 1px solid #dee2e6; }
            video::-webkit-media-controls-volume-slider, video::-webkit-media-controls-mute-button, video::-moz-media-controls-volume-slider, video::-moz-media-controls-mute-button, video::cue { display: none; }
            .results-table { width: 100%; max-width: 900px; margin: 2rem auto; border-collapse: collapse; }
            .results-table th, .results-table td { padding: 12px 15px; text-align: center; border-bottom: 1px solid #dee2e6; }
            .results-table thead th { background-color: #f8f9fa; font-weight: 600; border-top: 1px solid #dee2e6; border-bottom-width: 2px; }
            .results-table .method-name { text-align: left; font-weight: 500; }
            .best-score { background-color: #ffe0e0; }
            .second-best { background-color: #e0e8ff; }

            @media (max-width: 768px) {
                .navigation-controls { gap: 15px; }
                .nav-arrow { padding: 10px 14px; font-size: 16px; min-width: 45px; }
                .instance-dropdown { font-size: 14px; min-width: 120px; padding: 6px 10px; padding-right: 28px; }
                .comparison-row { flex-direction: column; align-items: center; }
                .video-column { min-width: 200px; }
            }
        </style>
    </head>
    <body>
        <div class="header-wrapper">
            <div class="header-container" id="header-container">
                <div class="header-content">
                    <h1 style="margin-top: 0px">Physics-Informed Representation Alignment</h1>
                    <p style="color: #3361aa; font-size: 20px;">
                        Grounding Video Diffusion Models in the Causal Principles of the Physical World
                    </p>
                    <div class="button-container">
                        <a href="https://arxiv.org/abs/YOUR_ARXIV_ID" class="button paper-link" target="_blank">
                            <span class="icon is-small"><i class="ai ai-arxiv"></i></span> arXiv
                        </a>
                        <a href="https://github.com/physics-informed-REPA" class="button" target="_blank">
                            <span class="icon is-small"><i class="fab fa-github"></i></span> Code
                        </a>
                        <a href="https://huggingface.co/datasets/physics-informed-REPA/pira_dataset" class="button" target="_blank">
                            <span class="icon is-small"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face logo" style="height: 1em;"></span> Dataset
                        </a>
                        <a href="https://huggingface.co/physics-informed-REPA/models" class="button" target="_blank">
                            <span class="icon is-small"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face logo" style="height: 1em;"></span> Models
                        </a>
                    </div>
                </div>
                <div class="header-image">
                    <img src="static/img/teaser.png" alt="PIRA Teaser Image" class="teaser-image">
                </div>
            </div>
        </div>
    <d-article>
        <div class="byline">
            <div class="byline-container">
                <div class="byline-column">
                    <h3>Authors</h3>
                    <p><a href="https://antragoudaras.github.io/" class="author-link" target="_blank">Antonios Tragoudaras<sup>△</sup></a></p>
                    <p><a href="https://zadaianchuk.github.io/" class="author-link" target="_blank">Andrii Zadaianchuk<sup>△</sup></a></p>
                    <p><a href="https://www.dcherniavskii.com/" class="author-link" target="_blank">Daniil Cherniavskii<sup>△</sup></a></p>
                    <p><a href="https://www.francescolocatello.com/" class="author-link" target="_blank">Francesco Locatello<sup>▲</sup></a></p>
                    <p><a href="https://www.egavves.com/" class="author-link" target="_blank">Efstratios Gavves<sup>△</sup></a></p>
                </div>
                <div class="byline-column">
                    <h3>Affiliations</h3>
                    <p><sup>△</sup> <a href="https://www.uva.nl/" class="affiliation-link" target="_blank">University of Amsterdam</a></p>
                    <p><sup>▲</sup> <a href="https://ista.ac.at/en/home/" class="affiliation-link" target="_blank">ISTA</a></p>
                </div>
                <div class="byline-column">
                    <h3>Date</h3>
                    <p>Sep. 2025</p>
                </div>
            </div>
        </div>

        <p class="text abstract">
            <strong>TL;DR:</strong> State-of-the-art Video Diffusion Models (VDMs) generate visually stunning content but often fail at basic physics, limiting their use as reliable world simulators. We introduce <strong>PIRA (Physics-Informed Representation Alignment)</strong>, a framework that teaches physics to pre-trained VDMs. Instead of using external, incompatible encoders, our key innovation is to re-purpose the VDM's <strong>own native VAE</strong> to encode physics proxies like depth and motion. This creates inherently compatible "teacher" signals, enabling stable and effective knowledge distillation. PIRA significantly improves the physical plausibility of generated videos, demonstrating a robust path toward more trustworthy world models.
        </p>
        <div class="icon-row">
            <a href="#method" class="icon-link">
                <i class="fas fa-cogs icon-jump" alt="PIRA Method Icon"></i>
                The PIRA<br>Framework
            </a>
            <a href="#results" class="icon-link">
                <i class="fas fa-chart-bar icon-jump" alt="Results Icon"></i>
                Results
            </a>
        </div>
        <p class="click-hint" style="width: 85%;">
            <i class="fas fa-hand-pointer" style="width: 1.5rem; color: #666;"></i>
            <strong>Click to jump to each section.</strong>
        </p>
        <hr>

        <div id="method">
            <h1 class="text">The PIRA Framework</h1>
            <p class="text">
                The core problem with current Video Diffusion Models (VDMs) is the "physics gap": they create beautiful videos that often defy the laws of nature. Existing methods to fix this are flawed—they either control the model from the outside without teaching it anything, or they use incompatible "teacher" models that lead to unstable training.
            </p>
            <p class="text">
                Our solution, PIRA, introduces a simple yet elegant architectural design. We distill physical knowledge by aligning the VDM's internal representations with physics-rich signals. Crucially, instead of using an external, black-box teacher, we re-purpose the VDM's <strong>own native 3D VAE</strong> as the teacher's encoder. By feeding it interpretable physics proxies—like optical flow (motion), depth maps (geometry), and segmentation masks (object shape)—we generate teacher representations that are, by definition, perfectly compatible with the student model's latent space. This bypasses latent mismatch issues and enables a stable, effective fine-tuning process.
            </p>
            <d-figure>
                <figure>
                    <img data-zoomable draggable="false" src="static/img/ppira.png" alt="PIRA Architecture Diagram">
                    <figcaption>
                        <strong>The PIRA Architecture.</strong> We feed explicit physics signals (masks, depth, optical flow) through the VDM's native 3D-VAE. This creates inherently compatible teacher representations that are used with a relational alignment loss to finetune the VDM, effectively instilling physical knowledge without training instability.
                    </figcaption>
                </figure>
            </d-figure>
        </div>

        <div id="results">
            <h1 class="text">Results</h1>
            
            <h2 class="text">Qualitative Comparison</h2>
            <p class="text">
                Visual results highlight the dramatic improvement PIRA brings. While the baseline model (CogVideoX) often generates videos where objects float, deform, or move unnaturally, our PIRA-finetuned model produces smooth, physically plausible free-fall trajectories that are nearly indistinguishable from the ground truth. This holds true for both in-distribution (ID) objects seen during training and, more importantly, for out-of-distribution (OOD) objects, demonstrating true generalization.
            </p>

            <!-- Interactive Video Comparison Section -->
            <div id="interactive-comparison" style="margin-top: 40px;">
                <h3 class="text" style="margin-bottom: 30px; text-align: center;">Interactive Video Comparison</h3>
                
                <div class="split-selector">
                    <button id="id-btn" class="split-btn active" onclick="switchSplit('id')">In-Distribution (ID)</button>
                    <button id="ood-btn" class="split-btn" onclick="switchSplit('ood')">Out-of-Distribution (OOD)</button>
                </div>
                
                <div class="instance-selector" style="margin-bottom: 30px;">
                    <div class="navigation-controls" id="navigation-controls">
                        <button id="prev-btn" class="nav-arrow" onclick="navigateInstance(-1)">←</button>
                        <select id="instance-dropdown" class="instance-dropdown" onchange="selectInstance()"></select>
                        <button id="next-btn" class="nav-arrow" onclick="navigateInstance(1)">→</button>
                    </div>
                </div>
                
                <div class="video-comparison">
                    <div class="comparison-row">
                        <div class="video-column">
                            <h4 class="method-label">Ground Truth</h4>
                            <video id="gt-video" controls autoplay loop playsinline muted style="width: 100%; max-width: 300px; border-radius: 8px;">
                                <source id="gt-source" src="" type="video/mp4">
                            </video>
                        </div>
                        <div class="video-column">
                            <h4 class="method-label">Baseline (CogVideoX)</h4>
                            <video id="cogvideo-video" controls autoplay loop playsinline muted style="width: 100%; max-width: 300px; border-radius: 8px;">
                                <source id="cogvideo-source" src="" type="video/mp4">
                            </video>
                        </div>
                        <div class="video-column">
                            <h4 class="method-label">PIRA (Ours)</h4>
                            <video id="pira-video" controls autoplay loop playsinline muted style="width: 100%; max-width: 300px; border-radius: 8px;">
                                <source id="pira-source" src="" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
            </div>

            <h2 class="text" style="margin-top: 60px;">Quantitative Results</h2>
            <p class="text">
                To move beyond visual inspection, we use our <strong>Morpheus</strong> benchmark, which provides explicit, physics-informed scores. It measures a model's adherence to the governing equations of motion (Dynamical Score) and its ability to conserve physical invariants like energy and momentum (Physical Invariance Score). The results below show that across all metrics, PIRA variants consistently and significantly outperform both the baseline and the TORA-based approach, confirming PIRA's superior ability to learn the underlying physical laws.
            </p>
            <table class="results-table">
                <thead>
                    <tr>
                        <th rowspan="2" class="method-name">Method</th>
                        <th colspan="3">In-Distribution (ID)</th>
                        <th colspan="3">Out-of-Distribution (OOD)</th>
                    </tr>
                    <tr>
                        <th>Dyn. (↑)</th>
                        <th>Phys. (↑)</th>
                        <th>Comb. (↑)</th>
                        <th>Dyn. (↑)</th>
                        <th>Phys. (↑)</th>
                        <th>Comb. (↑)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="method-name">CogVideoX (Baseline)</td>
                        <td>0.392</td>
                        <td>0.638</td>
                        <td>0.515</td>
                        <td>0.400</td>
                        <td>0.743</td>
                        <td>0.572</td>
                    </tr>
                    <tr>
                        <td class="method-name">SFT (Baseline)</td>
                        <td>0.672</td>
                        <td>0.782</td>
                        <td>0.727</td>
                        <td>0.636</td>
                        <td>0.822</td>
                        <td>0.729</td>
                    </tr>
                    <tr>
                        <td class="method-name">TORA-based</td>
                        <td>0.897</td>
                        <td>0.901</td>
                        <td>0.899</td>
                        <td>0.889</td>
                        <td>0.911</td>
                        <td>0.900</td>
                    </tr>
                    <tr>
                        <td colspan="7" style="background-color: #f8f9fa; font-weight: bold; text-align: left;">PIRA (Ours)</td>
                    </tr>
                    <tr>
                        <td class="method-name" style="padding-left: 30px;">Depth-based</td>
                        <td>0.930</td>
                        <td>0.912</td>
                        <td>0.921</td>
                        <td class="best-score">0.928</td>
                        <td>0.912</td>
                        <td>0.920</td>
                    </tr>
                    <tr>
                        <td class="method-name" style="padding-left: 30px;">Mask-based</td>
                        <td class="best-score">0.995</td>
                        <td class="best-score">0.939</td>
                        <td class="best-score">0.967</td>
                        <td>0.902</td>
                        <td class="best-score">0.939</td>
                        <td class="second-best">0.921</td>
                    </tr>
                    <tr>
                        <td class="method-name" style="padding-left: 30px;">Optical Flow-based</td>
                        <td class="second-best">0.979</td>
                        <td class="second-best">0.926</td>
                        <td class="second-best">0.953</td>
                        <td class="second-best">0.917</td>
                        <td class="second-best">0.938</td>
                        <td class="best-score">0.928</td>
                    </tr>
                </tbody>
            </table>
            <figcaption style="text-align: center; margin-top: 10px; font-size: 0.9em; color: #666;">
                <strong>Morpheus Scores:</strong> PIRA significantly outperforms baselines in modeling dynamics and conserving invariants. <span style="display: inline-block; width: 10px; height: 10px; background-color: #ffe0e0; border: 1px solid #ccc;"></span> Best scores are highlighted in red, <span style="display: inline-block; width: 10px; height: 10px; background-color: #e0e8ff; border: 1px solid #ccc;"></span> second-best in blue.
            </figcaption>
        </div>
        

    </d-article>
    <d-appendix>
        <h3>BibTeX</h3>
        <p class="bibtex">
            @mastersthesis{tragoudaras2025pira,<br>
            &nbsp;&nbsp;title={Physics-Informed Representation Alignment},<br>
            &nbsp;&nbsp;author={Tragoudaras, Antonios and Zadaianchuk, Andrii and Cherniavskii, Daniil and Locatello, Francesco and Gavves, Efstratios},<br>
            &nbsp;&nbsp;school={University of Amsterdam},<br>
            &nbsp;&nbsp;year={2025}<br>
            }
        </p>

        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
    </d-appendix>
    
    <d-bibliography src="bibliography.bib"></d-bibliography>
    <script src="./static/js/nav-bar.js"></script>
    
    <script type="text/javascript">
        // Interactive Video Comparison JavaScript
        let currentSplit = 'id';
        let currentInstance = 1;
        const totalInstances = 64;

        function populateDropdown() {
            const dropdown = document.getElementById('instance-dropdown');
            dropdown.innerHTML = '';
            for (let i = 1; i <= totalInstances; i++) {
                const option = document.createElement('option');
                option.value = i;
                option.textContent = `Instance ${i}`;
                dropdown.appendChild(option);
            }
            dropdown.value = currentInstance;
        }

        function updateArrowStates() {
            document.getElementById('prev-btn').disabled = currentInstance === 1;
            document.getElementById('next-btn').disabled = currentInstance === totalInstances;
        }

        function selectInstance() {
            currentInstance = parseInt(document.getElementById('instance-dropdown').value);
            updateArrowStates();
            updateVideos();
        }

        function navigateInstance(direction) {
            const newInstance = currentInstance + direction;
            if (newInstance >= 1 && newInstance <= totalInstances) {
                currentInstance = newInstance;
                document.getElementById('instance-dropdown').value = currentInstance;
                updateArrowStates();
                updateVideos();
            }
        }

        function switchSplit(split) {
            currentSplit = split;
            document.getElementById('id-btn').classList.toggle('active', split === 'id');
            document.getElementById('ood-btn').classList.toggle('active', split === 'ood');
            updateVideos();
        }
        
        function updateVideos() {
            const idx = currentInstance - 1;
            const basePath = `static/videos/interactive/${currentSplit}/`;
            
            const sources = {
                'gt-source': `${basePath}ground_truth/${idx}_fall.mp4`,
                'cogvideo-source': `${basePath}cogvideo_baselines/${idx}_fall.mp4`,
                'pira-source': `${basePath}pira_optical_flow/${idx}_fall.mp4`
            };
            
            for (const id in sources) {
                const sourceElement = document.getElementById(id);
                const videoElement = sourceElement.parentElement;
                sourceElement.src = sources[id];
                videoElement.load();
                videoElement.play().catch(e => console.error("Autoplay failed:", e));
            }
        }
        
        document.addEventListener('DOMContentLoaded', function() {
            populateDropdown();
            updateArrowStates();
            updateVideos();
            
            // Ensure all videos are muted for autoplay
            document.querySelectorAll('video').forEach(v => v.muted = true);
        });
    </script>
</body>
</html>