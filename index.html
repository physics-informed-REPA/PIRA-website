<!doctype html>
<html lang="en">
    <head>
        <title>Physics-Informed Representation Alignment (PIRA)</title>
        <link rel="icon" type="image/x-icon" href="static/img/icons/tower_icon.png">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:url" content="https://physics-informed-REPA.github.io/PIRA-website/" />
        <meta property="og:image" content="https://physics-informed-REPA.github.io/PIRA-website/static/img/preview.png" />
        <meta property="og:title" content="Physics-Informed Representation Alignment (PIRA)" />
        <meta property="og:description" content="A framework for instilling targeted, interpretable physical knowledge into pre-trained Video Diffusion Models by re-purposing the model's native VAE as a physics encoder." />

        <meta name="twitter:url" content="https://physics-informed-REPA.github.io/PIRA-website/" />
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:image" content="https://physics-informed-REPA.github.io/PIRA-website/static/img/preview.png" />
        <meta name="twitter:title" content="Physics-Informed Representation Alignment (PIRA)" />
        <meta name="twitter:description" content="A framework for instilling targeted, interpretable physical knowledge into pre-trained Video Diffusion Models by re-purposing the model's native VAE as a physics encoder." />

        <script src="./static/js/distill_template.v2.js"></script>

        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="https://d3js.org/d3-collection.v1.min.js"></script>
        <script src="https://rawgit.com/nstrayer/slid3r/master/dist/slid3r.js"></script>
        <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>

        <link rel="stylesheet" href="./static/css/style.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@9.0.0/swiper-bundle.min.css">
        <script src="https://cdn.jsdelivr.net/npm/swiper@9.0.0/swiper-bundle.min.js"></script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
        
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>

        <!-- medium zoom https://github.com/francoischalifour/medium-zoom -->
        <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js"></script>  <!-- jquery -->
        <script defer src="./static/js/medium-zoom.min.js"></script>
        <script defer src="./static/js/zoom.js"></script>
        
        <!-- Interactive Video Comparison & Table Styles -->
        <style>
            /* Section Header Styles - matching reference page */
            .section-header {
                font-size: 2rem;
                font-weight: 600;
                margin-top: 3rem;
                margin-bottom: 1rem;
                text-align: center;
                color: #333;
            }
            
            .subsection-header {
                font-size: 1.3rem;
                font-weight: 500;
                margin-top: 2rem;
                margin-bottom: 1rem;
                text-align: center;
                color: #333;
            }

            .split-selector { margin-bottom: 20px; text-align: center; }
            .split-btn { background: #f8f9fa; border: 2px solid #dee2e6; color: #495057; padding: 10px 20px; margin: 0 5px; border-radius: 6px; cursor: pointer; font-weight: 500; transition: all 0.3s ease; }
            .split-btn:hover { background: #e9ecef; border-color: #adb5bd; }
            .split-btn.active { background: #4a14f1; border-color: #4a14f1; color: white; }
            .navigation-controls { display: flex; align-items: center; justify-content: center; gap: 20px; max-width: 400px; margin: 0 auto; }
            .nav-arrow { background: #4a14f1; border: 2px solid #4a14f1; color: white; padding: 12px 16px; border-radius: 8px; cursor: pointer; font-weight: 600; font-size: 18px; transition: all 0.3s ease; min-width: 50px; }
            .nav-arrow:hover:not(:disabled) { background: #3a0fd1; border-color: #3a0fd1; transform: translateY(-2px); }
            .nav-arrow:disabled { background: #e9ecef; border-color: #dee2e6; color: #adb5bd; cursor: not-allowed; transform: none; }
            .instance-dropdown { background: white; border: 2px solid #4a14f1; color: #333; padding: 8px 12px; border-radius: 8px; cursor: pointer; font-weight: 600; font-size: 16px; min-width: 140px; text-align: center; transition: all 0.3s ease; appearance: none; background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 20 20'%3e%3cpath stroke='%234a14f1' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.5' d='m6 8 4 4 4-4'/%3e%3c/svg%3e"); background-position: right 8px center; background-repeat: no-repeat; background-size: 16px; padding-right: 32px; }
            .instance-dropdown:hover { border-color: #3a0fd1; transform: translateY(-1px); }
            .instance-dropdown:focus { outline: none; border-color: #3a0fd1; box-shadow: 0 0 0 3px rgba(74, 20, 241, 0.1); }
            .video-comparison { display: flex; justify-content: center; margin-top: 20px; }
            .comparison-row { display: flex; gap: 20px; flex-wrap: wrap; justify-content: center; max-width: 1000px; }
            .video-column { flex: 1; min-width: 250px; text-align: center; }
            .method-label { margin-bottom: 10px; font-weight: 600; color: #333; font-size: 14px; }
            .video-column video { box-shadow: 0 2px 8px rgba(0,0,0,0.1); border: 1px solid #dee2e6; }
            video::-webkit-media-controls-volume-slider, video::-webkit-media-controls-mute-button, video::-moz-media-controls-volume-slider, video::-moz-media-controls-mute-button, video::cue { display: none; }
            .results-table { width: 100%; max-width: 900px; margin: 2rem auto; border-collapse: collapse; }
            .results-table th, .results-table td { padding: 12px 15px; text-align: center; border-bottom: 1px solid #dee2e6; }
            .results-table thead th { background-color: #f8f9fa; font-weight: 600; border-top: 1px solid #dee2e6; border-bottom-width: 2px; }
            .results-table .method-name { text-align: left; font-weight: 500; }
            .best-score { background-color: #ffe0e0; }
            .second-best { background-color: #e0e8ff; }
            .results-table .method-name a:hover {
                text-decoration: underline;
                color: #4a14f1;
            }

            /* Compact Authors & Affiliations Section - Header Version */
            .authors-section {
                text-align: center;
                margin: 1.5rem 0 2rem 0;
                padding: 0.5rem 1rem;
            }

            .authors-section .authors {
                margin-top: 0.5rem;
                line-height: 1.6;
                font-size: 1.1rem;
            }

            .authors-section .authors a {
                text-decoration: none;
                color: #1e293b;
                font-weight: 500;
                transition: color 0.2s ease-in-out;
            }

            .authors-section .authors a:hover {
                color: #0f172a;
                text-decoration: underline;
            }

            .authors-section .affiliations {
                color: #475569;
                margin-top: 0.75rem;
                font-size: 0.95rem;
            }

            .authors-section .affiliations a {
                text-decoration: none;
                color: #475569;
                transition: color 0.2s ease-in-out;
            }

            .authors-section .affiliations a:hover {
                color: #1e293b;
                text-decoration: underline;
            }

            .authors-section .date {
                color: #64748b;
                margin-top: 0.5rem;
                font-size: 0.9rem;
            }

            .tldr-section {
                margin-top: 1.5rem;
                text-align: center;
                font-size: 0.95rem;
                color: #475569;
                line-height: 1.5;
                max-width: 600px;
                margin-left: auto;
                margin-right: auto;
            }

            @media (max-width: 768px) {
                .section-header { font-size: 1.8rem; }
                .subsection-header { font-size: 1.2rem; }
                .navigation-controls { gap: 15px; }
                .nav-arrow { padding: 10px 14px; font-size: 16px; min-width: 45px; }
                .instance-dropdown { font-size: 14px; min-width: 120px; padding: 6px 10px; padding-right: 28px; }
                .comparison-row { flex-direction: column; align-items: center; }
                .video-column { min-width: 200px; }
            }

            /* Content wrapper for centering */
            .content-wrapper {
                max-width: 800px;
                margin: 0 auto;
                background: var(--background-primary, #fff);
                position: relative;
                z-index: 1;
                box-sizing: border-box;
            }

            /* Citation section styling */
            .citation-section {
                text-align: center;
                margin: 2rem 0;
            }

            .citation-box {
                background: var(--background-secondary, #f9f9f9);
                border: 1px solid var(--border-color, #ccc);
                text-align: left;
                border-radius: 5px;
                padding: 1rem;
                position: relative;
                margin: 1rem auto;
                max-width: 600px;
            }

            .citation-pre {
                margin: 0;
                font-family: monospace;
                font-size: 0.9rem;
                white-space: pre-wrap;
                word-wrap: break-word;
            }
        </style>
    </head>
    <body>
        <div class="header-wrapper">
            <div class="header-container" id="header-container">
                <div class="header-content">
                    <h1 style="margin-top: 0px">Physics-Informed Representation Alignment</h1>
                    <div class="authors-section">
                        <div class="authors">
                            <a href="https://antragoudaras.github.io/" target="_blank">Antonios Tragoudaras</a><sup>1</sup>,
                            <a href="https://zadaianchuk.github.io/" target="_blank">Andrii Zadaianchuk</a><sup>1</sup>,
                            <a href="https://www.dcherniavskii.com/" target="_blank">Daniil Cherniavskii</a><sup>1</sup>,
                            <a href="https://www.francescolocatello.com/" target="_blank">Francesco Locatello</a><sup>2</sup>,
                            <a href="https://www.egavves.com/" target="_blank">Efstratios Gavves</a><sup>1</sup>
                        </div>
                        <div class="affiliations">
                            <sup>1</sup> <a href="https://www.uva.nl/" target="_blank">University of Amsterdam</a> &nbsp;&nbsp; <sup>2</sup> <a href="https://ista.ac.at/en/home/" target="_blank">ISTA</a>
                        </div>
                        <div class="date">Oct. 2025</div>
                    </div>
                    <div class="button-container">
                        <!-- <a href="https://arxiv.org/abs/YOUR_ARXIV_ID" class="button paper-link" target="_blank">
                            <span class="icon is-small"><i class="ai ai-arxiv"></i></span> arXiv
                        </a> -->
                        <!-- <a href="https://github.com/physics-informed-REPA" class="button" target="_blank">
                            <span class="icon is-small"><i class="fab fa-github"></i></span> Code (Coming Soon!)
                        </a> -->
                        <a href="https://huggingface.co/datasets/physics-informed-REPA/pira_dataset" class="button" target="_blank">
                            <span class="icon is-small"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face logo" style="height: 1em;"></span> Dataset
                        </a>
                        <a href="https://huggingface.co/physics-informed-REPA/models" class="button" target="_blank">
                            <span class="icon is-small"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face logo" style="height: 1em;"></span> Models
                        </a>
                    </div>
                    <div class="tldr-section">
                        <strong>TL;DR:</strong> State-of-the-art Video Diffusion Models (VDMs) are great at generating visually appealing videos but struggle with understanding physical phenomena. We introduce <strong>PIRA</strong>, a simple yet stable method to teach physics to pre-trained VDMs. Our key idea is to use the VDM's <strong>own native VAE encoder(tokenizer)</strong> to process proxy physics-centric signals (like motion, depth, and segmentation masks), for creating representations that the model can easily learn from. PIRA effectively closes the gap between the VDM's visual and its physical reasoning capabilities.
                    </div>
                </div>
                <div class="header-image">
                    <img src="static/img/teaser_no_watermark.png" alt="PIRA Teaser Image" class="teaser-image">
                </div>
            </div>
        </div>
    <d-article>

        <div id="abstract">
            <h2 class="section-header">Abstract</h2>
            <p class="text">
                Envisioning large-scale Video Generative Models (VGMs) as world simulators represents a significant frontier in Artificial Intelligence, promising to empower the next generation of Physical AI; enabling embodied agents to learn, plan, and simulate actions in a safe, scalable digital twin of our physical world. Nevertheless, the realization of this vision is hindered by the models' limited understanding of physics. Concurrent works have revealed that these models have only developed immature physics reasoning capabilities, as an emerging from their generative pre-training on massive, unstructured video datasets. The aggregated knowledge is a fragile imitation of visual pattern visual patterns present in the training data, rather than a truly grasp of the underlying physical dynamics. Thus, despite their unprecedented visual fidelity abilities in generating videos, these models frequently defy fundamental physical laws. Existing methods struggle to bridge this gap: imposing explicit control at inference time does not enhance the model's intrinsic knowledge, while prior knowledge distillation methods via representation alignment relies on opaque, black-box vision encoders, suffers from training instabilities.
            </p>
            <p class="text">
                To address these limitations, we introduce <strong>P</strong>hysics-<strong>I</strong>nformed <strong>R</strong>epresentation <strong>A</strong>lignment (PIRA), a framework for instilling targeted, interpretable physical knowledge into pre-trained Video Diffusion Models. Our approach is based on distilling knowledge from physics-rich proxy signals—representations of the observable consequences of physical laws, such as an optical flow field, relative depths, segmentation masks serving as a proxy of an object's state variable. This is a scalable approach for teaching simple  motions that adhere to Newtonian Dynamic laws. In our work we focus on items falling under normal gravity. The core of our design is to re-purpose the VDM's native VAE encoder to create inherently compatible <em>teacher</em> representations from these signals. Developing PIRA also necessitated a more principled evaluation of physical plausibility. We identify that existing benchmarks suffer from fundamental flaws, such as the subjectivity of Vision Question Answering based scores or the false negatives produced by single-outcome trajectory matching. We therefore introduce a novel, evaluation strategy that moves beyond these limitations by measuring a generated video's adherence to governing dynamical equations and conservation of physical invariants. Through extensive experiments, our findings reveal that PIRA is highly effective at teaching Video Diffusion Models to respect underlying physical principles. This work marks a significant step toward grounding Video Diffusion Models in some form of causal principles of the physical world, enhancing their reliability and trustworthiness as world simulators.
            </p>
        </div>
        <hr>

        <!-- <div id="method">
            <h1 class="text">The PIRA Framework</h1>
            <p class="text">
                The core problem with current Video Diffusion Models (VDMs) is the "physics gap": they create beautiful videos that often defy the laws of nature. Existing methods to fix this are flawed—they either control the model from the outside without teaching it anything, or they use incompatible "teacher" models that lead to unstable training.
            </p>
            <p class="text">
                Our solution, PIRA, introduces a simple yet elegant architectural design. We distill physical knowledge by aligning the VDM's internal representations with physics-rich signals. Crucially, instead of using an external, black-box teacher, we re-purpose the VDM's <strong>own native 3D VAE</strong> as the teacher's encoder. By feeding it interpretable physics proxies—like optical flow (motion), depth maps (geometry), and segmentation masks (object shape)—we generate teacher representations that are, by definition, perfectly compatible with the student model's latent space. This bypasses latent mismatch issues and enables a stable, effective fine-tuning process.
            </p>
            <d-figure>
                <figure>
                    <img data-zoomable draggable="false" src="static/img/ppira.png" alt="PIRA Architecture Diagram">
                    <figcaption>
                        <strong>The PIRA Architecture.</strong> We feed explicit physics signals (masks, depth, optical flow) through the VDM's native 3D-VAE. This creates inherently compatible teacher representations that are used with a relational alignment loss to finetune the VDM, effectively instilling physical knowledge without training instability.
                    </figcaption>
                </figure>
            </d-figure>
        </div> -->

        <div id="results">
            <h2 class="section-header">Video Examples</h2>
            
            <p class="text">
                Visual results highlight the dramatic improvement PIRA brings. While the baseline model (CogvideoX-5B-I2V<d-cite key="yang2024cogvideox"></d-cite>) often generates videos where objects float, deform, or move unnaturally, our PIRA-finetuned model produces smooth, physically plausible free-fall trajectories that are nearly indistinguishable from the ground truth. This holds true for both in-distribution (ID) objects seen during training and, more importantly, for out-of-distribution (OOD) objects, demonstrating true generalization.
            </p>

            <!-- Interactive Video Comparison Section -->
            <div id="interactive-comparison" style="margin-top: 40px;">
                <div class="split-selector">
                    <button id="id-btn" class="split-btn active" onclick="switchSplit('id')">In-Distribution (ID)</button>
                    <button id="ood-btn" class="split-btn" onclick="switchSplit('ood')">Out-of-Distribution (OOD)</button>
                </div>
                
                <div class="instance-selector" style="margin-bottom: 30px;">
                    <div class="navigation-controls" id="navigation-controls">
                        <button id="prev-btn" class="nav-arrow" onclick="navigateInstance(-1)">←</button>
                        <select id="instance-dropdown" class="instance-dropdown" onchange="selectInstance()"></select>
                        <button id="next-btn" class="nav-arrow" onclick="navigateInstance(1)">→</button>
                    </div>
                </div>
                
                <div class="video-comparison">
                    <div class="comparison-row">
                        <div class="video-column">
                            <h4 class="method-label">Ground Truth</h4>
                            <video id="gt-video" controls autoplay loop playsinline muted style="width: 100%; max-width: 300px; border-radius: 8px;">
                                <source id="gt-source" src="" type="video/mp4">
                            </video>
                        </div>
                        <div class="video-column">
                            <h4 class="method-label">Baseline (CogvideoX-5B-I2V)</h4>
                            <video id="cogvideo-video" controls autoplay loop playsinline muted style="width: 100%; max-width: 300px; border-radius: 8px;">
                                <source id="cogvideo-source" src="" type="video/mp4">
                            </video>
                        </div>
                        <div class="video-column">
                            <h4 class="method-label">PIRA (Ours)</h4>
                            <video id="pira-video" controls autoplay loop playsinline muted style="width: 100%; max-width: 300px; border-radius: 8px;">
                                <source id="pira-source" src="" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
            </div>

            <h2 class="section-header" style="margin-top: 60px;">Quantifying Physical Reasoning</h2>
            <p class="text">
                To move beyond visual inspection, we use <strong><a href="https://arxiv.org/abs/2504.02918" target="_blank">Morpheus</a></strong> benchmark, which provides explicit, physics-informed scores. It measures a model's adherence to the governing equations of motion (Dynamical Score) and its ability to conserve physical invariants like energy and momentum (Physical Invariance Score). The results below show that across all metrics, PIRA variants consistently and significantly outperform both the baseline and the Specialized Motion Encoder approach, based on <a href="https://arxiv.org/abs/2412.10743" target="_blank">TORA</a>, confirming PIRA's superior ability to learn the underlying physical laws.
            </p>
            <table class="results-table">
                <thead>
                    <tr>
                        <th rowspan="2" class="method-name">Method</th>
                        <th colspan="3">In-Distribution (ID)</th>
                        <th colspan="3">Out-of-Distribution (OOD)</th>
                    </tr>
                    <tr>
                        <th>Dyn. (↑)</th>
                        <th>Phys. (↑)</th>
                        <th>Comb. (↑)</th>
                        <th>Dyn. (↑)</th>
                        <th>Phys. (↑)</th>
                        <th>Comb. (↑)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="method-name"><a href="https://arxiv.org/abs/2408.06072" target="_blank">CogvideoX-5B-I2V</a> (Baseline)</td>
                        <td>0.392</td>
                        <td>0.638</td>
                        <td>0.515</td>
                        <td>0.400</td>
                        <td>0.743</td>
                        <td>0.572</td>
                    </tr>
                    <tr>
                        <td class="method-name">Finetuned <a href="https://arxiv.org/abs/2408.06072" target="_blank">CogvideoX-5B-I2V</a> (Baseline)</td>
                        <td>0.672</td>
                        <td>0.782</td>
                        <td>0.727</td>
                        <td>0.636</td>
                        <td>0.822</td>
                        <td>0.729</td>
                    </tr>
                    <tr>
                        <td class="method-name"><a href="https://arxiv.org/abs/2412.10743" target="_blank">Specialized Motion Encoder </td>
                        <td>0.897</td>
                        <td>0.901</td>
                        <td>0.899</td>
                        <td>0.889</td>
                        <td>0.911</td>
                        <td>0.900</td>
                    </tr>
                    <tr>
                        <td colspan="7" style="background-color: #f8f9fa; font-weight: bold; text-align: left;">PIRA (Ours)</td>
                    </tr>
                    <tr>
                        <td class="method-name" style="padding-left: 30px;">Depth-based</td>
                        <td>0.930</td>
                        <td>0.912</td>
                        <td>0.921</td>
                        <td class="best-score">0.928</td>
                        <td>0.912</td>
                        <td>0.920</td>
                    </tr>
                    <tr>
                        <td class="method-name" style="padding-left: 30px;">Mask-based</td>
                        <td class="best-score">0.995</td>
                        <td class="best-score">0.939</td>
                        <td class="best-score">0.967</td>
                        <td>0.902</td>
                        <td class="best-score">0.939</td>
                        <td class="second-best">0.921</td>
                    </tr>
                    <tr>
                        <td class="method-name" style="padding-left: 30px;">Optical Flow-based</td>
                        <td class="second-best">0.979</td>
                        <td class="second-best">0.926</td>
                        <td class="second-best">0.953</td>
                        <td class="second-best">0.917</td>
                        <td class="second-best">0.938</td>
                        <td class="best-score">0.928</td>
                    </tr>
                </tbody>
            </table>
            <figcaption style="text-align: center; margin-top: 10px; font-size: 0.9em; color: #666;">
                <strong><a href="https://arxiv.org/abs/2504.02918" target="_blank">Morpheus</a> Scores:</strong> PIRA significantly outperforms baselines in modeling dynamics and conserving invariants. <span style="display: inline-block; width: 10px; height: 10px; background-color: #ffe0e0; border: 1px solid #ccc;"></span> Best scores are highlighted in red, <span style="display: inline-block; width: 10px; height: 10px; background-color: #e0e8ff; border: 1px solid #ccc;"></span> second-best in blue.
            </figcaption>
        </div>
        

    </d-article>
    <div class="content-wrapper">
        <div class="citation-section">
            <h2>BibTeX</h2>
            <div class="citation-box">
                <pre class="citation-pre">@misc{tragoudaras2025pira,
  title={Physics-Informed Representation Alignment},
  author={Antonios Tragoudaras and Andrii Zadaianchuk and Daniil Cherniavskii and Francesco Locatello and Efstratios Gavves},
  year={2025},
  howpublished={\url{@https://physics-informed-REPA.github.io/PIRA-website/}},
  note={Project website}
}</pre>
            </div>
        </div>
    </div>

    <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
    </d-appendix>
    
    <d-bibliography src="bibliography.bib"></d-bibliography>
    <script src="./static/js/nav-bar.js"></script>
    
    <script type="text/javascript">
        // Interactive Video Comparison JavaScript
        let currentSplit = 'id';
        let currentInstance = 1;
        const totalInstances = 64;

        function populateDropdown() {
            const dropdown = document.getElementById('instance-dropdown');
            dropdown.innerHTML = '';
            for (let i = 1; i <= totalInstances; i++) {
                const option = document.createElement('option');
                option.value = i;
                option.textContent = `Instance ${i}`;
                dropdown.appendChild(option);
            }
            dropdown.value = currentInstance;
        }

        function updateArrowStates() {
            document.getElementById('prev-btn').disabled = currentInstance === 1;
            document.getElementById('next-btn').disabled = currentInstance === totalInstances;
        }

        function selectInstance() {
            currentInstance = parseInt(document.getElementById('instance-dropdown').value);
            updateArrowStates();
            updateVideos();
        }

        function navigateInstance(direction) {
            const newInstance = currentInstance + direction;
            if (newInstance >= 1 && newInstance <= totalInstances) {
                currentInstance = newInstance;
                document.getElementById('instance-dropdown').value = currentInstance;
                updateArrowStates();
                updateVideos();
            }
        }

        function switchSplit(split) {
            currentSplit = split;
            document.getElementById('id-btn').classList.toggle('active', split === 'id');
            document.getElementById('ood-btn').classList.toggle('active', split === 'ood');
            updateVideos();
        }
        
        function updateVideos() {
            const idx = currentInstance - 1;
            const basePath = `static/videos/interactive/${currentSplit}/`;
            
            const sources = {
                'gt-source': `${basePath}ground_truth/${idx}_fall.mp4`,
                'cogvideo-source': `${basePath}cogvideo_baselines/${idx}_fall.mp4`,
                'pira-source': `${basePath}pira_optical_flow/${idx}_fall.mp4`
            };
            
            for (const id in sources) {
                const sourceElement = document.getElementById(id);
                const videoElement = sourceElement.parentElement;
                sourceElement.src = sources[id];
                videoElement.load();
                videoElement.play().catch(e => console.error("Autoplay failed:", e));
            }
        }
        
        document.addEventListener('DOMContentLoaded', function() {
            populateDropdown();
            updateArrowStates();
            updateVideos();
            
            // Ensure all videos are muted for autoplay
            document.querySelectorAll('video').forEach(v => v.muted = true);
        });
    </script>
</body>
</html>